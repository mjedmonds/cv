%----------------------------------------------------------------------------------------
%	SECTION TITLE
%----------------------------------------------------------------------------------------

\cvsection{Research Experience}

%----------------------------------------------------------------------------------------
%	SECTION CONTENT
%----------------------------------------------------------------------------------------

\begin{cventries}

%------------------------------------------------

% STICK TO "accomplished X measured by Y by doing Z" for the descriptions

\cventry
{Computer Science Department, UCLA}
{Graduate Student Researcher}
{Los Angeles, CA}
{Sep 2016 – Present}
{
\begin{justify}
Humans build generalizable and explainable representations of their environment through interaction, observation, imitation, intervention, and language. The following research produced from a collaborative, team-based lab explores how artificial agents can use these five concepts to learn robust and transferable representations of tasks and environments.
\end{justify}
%
\begin{justify}
\entrysmalltitlestyle{Imitation learning: Training a robot to twist open a medicine bottle}
\end{justify}
\vspace{-1mm}
\begin{cvitems}
  \item Captured the complex human hand forces required to open seven different medicine bottles with a tactical glove covered in IMUs (inertial measurement units) and force sensors.
  \item Constructed robot action planner using a haptic network, And-Or Graph, and the generalized Earley parser.
  \item \underline{Result}: Questioned the common structure humans see in the procedure to open any medicine bottle vs. the widely varying forces and action sequences used by the robot for each bottle. This prompted an investigation of abstraction and generalization:
\end{cvitems}
%
\begin{justify}
\entrysmalltitlestyle{Causal learning: Virtual escape room to examine how humans and AI learn transferable causal representations}
\end{justify}
\vspace{-1mm}
\begin{cvitems}
  \item Built virtual "escape room" to test causal generalization; surface-level features change room to room while each room is governed by a common abstract causal structure (series of levers) that describes the required actions to "unlock" the room.
  \item Ran human subject experiments to verify human learners are capable of discovering the correct abstract causal structure.
  \item Built hierarchical Bayesian model to achieve similar performance as human learners.  This causal model was able to solve the escape room while seven state-of-the-art model-free reinforcement learning algorithms failed at the task.
  \item \underline{Result}: Both structural abstraction and feature generalization are critical for transfer learning and generalization.
\end{cvitems}
%
\begin{justify}
\entrysmalltitlestyle{Explainable AI: How can robots explain their behavior to foster trust from humans?}
\end{justify}
\vspace{-1mm}
\begin{cvitems}
  \item Expanded prior imitation learning work by building human-understandable visual interfaces to describe the robot's haptic network and And-Or Graph.
  \item Showed that robots may need to "think" one way to complete a task but another way to explain their behavior: the explanations that best fostered trust were not the model components that best aided the robot to achieve the task.
  \item \underline{Result}: Consider explainability as a first-class citizen when building AI systems that interact with humans.
\end{cvitems}
%
\begin{justify}
\entrysmalltitlestyle{Representation learning: The role of language in building generalizable representations}
\end{justify}
\vspace{-1mm}
\begin{cvitems}
  \item Created a virtual playground for embodied AI to learn interpretable, common-sense representations of its environment.
  \item Built a simulated environment using Unreal Engine 4 (UE4) that couples language and vision in a scene graph.
  \item Devised a dataset consisting of images, language labels, and object segmentation.
  \item \underline{Ongoing}: Build representation learning algorithm to use language labels to decompose latent encoding of the environment.
\end{cvitems}
}

%------------------------------------------------

% \cventry
% {Graduate Student Researcher; Center for Vision, Cognition, Learning, and Autonomy (VCLA)}
% {Causal Transfer Learning}
% {Los Angeles, CA}
% {Sep 2017 – Present}
% {
% \begin{cvitems}
% \item Examining how causal knowledge can be incorporated into reinforcement learning to enable better knowledge transfer across task and environment domains.
% \item Matched human causal learning performance by decomposing causal representations into two Bayesian components: a bottom-up associative learning scheme and a top-down structure learning scheme.
% \item Studied how humans perform in causal transfer tasks and compared performance against state-of-the-art reinforcement learning algorithms.
% \end{cvitems}
% }

%------------------------------------------------

% \cventry
% {Graduate Student Researcher; Center for Vision, Cognition, Learning, and Autonomy (VCLA)}
% {Fostering Human Trust through Explainable AI (XAI)}
% {Los Angeles, CA}
% {Jan 2019 – Present}
% {
% \begin{cvitems}
% % \item Investigating the form of explanations that foster human trust and the computational models that support such explanations.
% \item Developing a computational model to generate explanations for robot behavior based on theory-of-mind (ToM) in a communicative learning setting.
% \item Fostered trust between robots and humans in an imitation learning setting by providing sequential, action-level explanations to human subjects. This work built off of my work on imitation learning using tactile feedback.
% \end{cvitems}
% }

%------------------------------------------------

% \cventry
% {Graduate Student Researcher; Center for Vision, Cognition, Learning, and Autonomy (VCLA)}
% {Transferrable Representation Learning using Language Supervision}
% {Los Angeles, CA}
% {Jun 2019 – Present}
% {
% \begin{cvitems}
% \item Developing a photorealistic virtual environment (based on Unreal Engine) that provides semantic language labels for objects and actions occurring in the virtual agent's field of view.
% \item Examining the role of language in building generalizable, commonsense representations of the environment.
% % \item This work is inspired by research in child development and aims to build commonsense knowledge from interaction.
% \end{cvitems}
% }

%------------------------------------------------

% \cventry
% {Graduate Student Researcher; Center for Vision, Cognition, Learning, and Autonomy (VCLA)}
% {Imitation Learning using Tactile Feedback}
% {Los Angeles, CA}
% {Sep 2015 – Sep 2017}
% {
% \begin{cvitems}
% \item Transferred visually latent causal changes from a human demonstrator to a robot using a tactile glove, an And-Or graph, and neural networks.
% \item Utilized a manipulation policy that encodes long-term temporal constraints using an And-Or graph and leverages haptic feedback from human demonstrators to incorporate real-time sensor data.
% \item Deployed robot localization on a ROS-based Baxter robot combining SLAM (using RGB-D and LIDAR), wheel odometry, and IMU data through Kalman filtering.
% \end{cvitems}
% }

%------------------------------------------------

% \cventry
% {Undergraduate Researcher; Air Force Research Lab (AFRL)}
% {Declarative Memory Acceleration}
% {Dayton, OH}
% {May 2014 – Sep 2015}
% {
% \begin{cvitems}
% \item Accelerated the declarative memory module of AFRL's CECEP cognitive architecture (based on \href{http://act-r.psy.cmu.edu/}{ACT-R}) by leveraging the parallelization of CUDA, yielding a 100x speedup over the fastest existing implementation.
% \end{cvitems}
% }

%------------------------------------------------

\end{cventries}