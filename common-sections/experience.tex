%----------------------------------------------------------------------------------------
%	SECTION TITLE
%----------------------------------------------------------------------------------------

\cvsection{Professional and Research Experience}

%----------------------------------------------------------------------------------------
%	SECTION CONTENT
%----------------------------------------------------------------------------------------

\begin{cventries}

\cventry
{Cruise Automation}
{Senior Software Engineer}
{San Francisco, CA}
{Oct 2021 - Present}
{
\begin{cvitems}
\item Working at the intersection of machine learning and planning for the Trajectory Planning team.
\item Increased several project-specific metrics with improvements ranging from 9\% to 34\%.
\item Using TensorFlow, Google Cloud, and ROS to deploy ML models to cars driving on the road today!
\end{cvitems}
}

\cventry
{Center for AI and Robot Autonomy (CARA)}
{Director and President}
{Los Angeles, CA}
{Mar 2021 - Present}
{
\begin{cvitems}
\item Define updated mission and vision statements, seek alternative funding, and file paperwork to maintain 501(c)(3) status.
\end{cvitems}
}

\cventry
{Computer Science Department, UCLA}
{Graduate Student Researcher}
{Los Angeles, CA}
{Sep 2016 - Sep 2021}
{
\begin{justify}
Humans build generalizable and explainable representations of their environment through interaction, observation, imitation, intervention, and language. The following research produced from a collaborative, team-based lab explores how artificial agents can use these five concepts to learn robust and transferable representations of tasks and environments.
\end{justify}
%
\begin{justify}
\entrysmalltitlestyleit{Imitation learning: Training a robot to twist open a medicine bottle}
\end{justify}
\vspace{-1mm}
\begin{cvitems}
  \item Captured the complex human hand forces required to open seven different medicine bottles with a tactical glove covered in IMUs (inertial measurement units) and force sensors.
  \item Constructed robot action planner using a haptic network, And-Or Graph, and the generalized Earley parser.
  \item \underline{Result}: Questioned the common structure humans see in the procedure to open any medicine bottle vs. the widely varying forces and action sequences used by the robot for each bottle. This prompted an investigation of abstraction and generalization.
\end{cvitems}
%
\begin{justify}
\entrysmalltitlestyleit{Causal learning: Virtual escape room to examine how humans and AI learn transferable causal representations}
\end{justify}
\vspace{-1mm}
\begin{cvitems}
  \item Built virtual "escape rooms" to test causal generalization; while the surface-Â­level features change, all rooms are governed by a common abstract causal structure (series of levers) that describes the required actions to "unlock" the room.
  \item Ran human subject experiments to verify human learners are capable of discovering the correct abstract causal structure.
  \item Built hierarchical Bayesian model to achieve similar performance as human learners.  This causal model was able to solve the escape room while seven state-of-the-art model-free reinforcement learning algorithms failed at the task.
  \item \underline{Result}: Both structural abstraction and feature generalization are critical for transfer learning and generalization.
\end{cvitems}
%
\begin{justify}
\entrysmalltitlestyleit{Explainable AI: How can robots explain their behavior to foster trust from humans?}
\end{justify}
\vspace{-1mm}
\begin{cvitems}
  \item Expanded prior imitation learning work by building human-understandable visual interfaces to describe the robot's haptic network and And-Or Graph.
  \item Showed that robots may need to "think" one way to complete a task, but another way to explain their behavior; the explanations that best fostered trust were not the model components that best aided the robot to achieve the task.
  \item \underline{Result}: Consider explainability as a first-class citizen when building AI systems that interact with humans.
\end{cvitems}
%
\newpage
\begin{justify}
\entrysmalltitlestyleit{Representation learning: The role of language in building generalizable representations}
\end{justify}
\vspace{-1mm}
\begin{cvitems}
  \item Created a virtual playground for embodied AI to learn interpretable, common-sense representations of its environment.
  \item Built a simulated environment using Unreal Engine 4 (UE4) that couples language and vision in a scene graph.
  \item Devised a dataset consisting of images, language labels, and object segmentation.
  \item \underline{Ongoing}: Build representation learning algorithm to use language labels to decompose latent encoding of the environment.
\end{cvitems}
}

\cventry
{Center for AI and Robot Autonomy (CARA)}
{Robotics Research Engineer Intern}
{Los Angeles, CA}
{Jun 2018 - Mar 2020}
{
\begin{cvitems}
\item Worked on representation learning project to couple vision and language (details under UCLA Graduate Student Researcher).
\end{cvitems}
}

\cventry
{Air Force Research Lab (AFRL)}
{Undergraduate Researcher}
{Dayton, OH}
{May 2014 - Sep 2015}
{
\begin{cvitems}
\item Conducted Declarative Memory (semantic knowledge retrieval system) research for the ACT-R cognitive architecture.
\item Architected a new declarative memory system using CUDA, thread pools, parsers, and inter-process communication (IPC).
\item Continued project work between summers as undergrad thesis research.
\item \underline{Result}: Parallelized declarative retrievals; yielded a 100x speedup over the fastest existing implementation.
\end{cvitems}
}

\cventry
{Aviation Department, Garmin International}
{Software Engineering Intern}
{Olathe, KS}
{May 2013 - Aug 2013}
{
\begin{cvitems}
\item Automated the testing process for small craft airplane ACARS systems that send timed status messages to ground stations.
\item Reduced testing time by 40\% and saved hundreds of vendor certification testing hours by optimizing simulation timing protocols and adhering to FAA safety standards.
\end{cvitems}
}

\end{cventries}